{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nike Sales Data Exploratory Data Analysis (EDA) Project\n",
    "\n",
    "This project demonstrates a professional EDA workflow using a real-world Nike sales dataset.\n",
    "It covers data exploration, cleaning, analysis, and insight generationâ€”ideal for showcasing Python, pandas, and analytical skills to employers.\n",
    "\n",
    "**Author:** Samrah Far\n",
    "\n",
    "## ðŸ“Œ Table of Contents\n",
    "1. [Project Overview](#project-overview)\n",
    "2. [Importing Libraries](#importing-libraries)\n",
    "3. [Loading the Dataset](#loading-the-dataset)\n",
    "4. [Initial Data Exploration](#initial-data-exploration)\n",
    "5. [Data Cleaning](#data-cleaning)\n",
    "6. [Univariate Analysis](#univariate-analysis)\n",
    "7. [Bivariate Analysis](#bivariate-analysis)\n",
    "8. [Handling Outliers](#handling-outliers)\n",
    "9. [Feature Scaling / Transformation](#feature-scaling--transformation)\n",
    "10. [Insights & Business Recommendations](#insights--business-recommendations)\n",
    "11. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Overview <a name=\"project-overview\"></a>\n",
    "\n",
    "This project demonstrates advanced Exploratory Data Analysis (EDA) using Nike Sales data.\n",
    "\n",
    "**Objectives:**\n",
    "- Uncover trends and data quality issues\n",
    "- Extract actionable insights\n",
    "- Support business decisions with analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries <a name=\"importing-libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd                # Data manipulation and analysis\n",
    "import matplotlib.pyplot as plt    # Data visualization\n",
    "import seaborn as sns              # Enhanced statistical plots\n",
    "import scipy.stats as stats        # Statistical tools\n",
    "import numpy as np                 # Numerical computing\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the Dataset <a name=\"loading-the-dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the sales data\n",
    "df = pd.read_csv('Nike_Sales_Uncleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preview the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preview the last few rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial Data Exploration <a name=\"initial-data-exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inspect data types, missing values, and overall structure\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate summary statistics for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Missing values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning <a name=\"data-cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove rows where critical numeric data is missing (Units_Sold or MRP)\n",
    "df_clean = df.dropna(subset=['Units_Sold', 'MRP']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fix inconsistent date formats in 'Order_Date'\n",
    "def parse_date(date):\n",
    "    if pd.isnull(date):\n",
    "        return np.nan\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d-%m-%Y\", \"%Y/%m/%d\", \"%d/%m/%Y\", \"%d-%m-%y\", \"%Y-%d-%m\"):\n",
    "        try:\n",
    "            return pd.to_datetime(date, format=fmt)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.to_datetime(date, errors='coerce')\n",
    "\n",
    "df_clean['Order_Date'] = df_clean['Order_Date'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill missing Discount_Applied with 0 (assume no discount)\n",
    "df_clean['Discount_Applied'] = df_clean['Discount_Applied'].fillna(0)\n",
    "\n",
    "# Fill missing Size with 'Unknown'\n",
    "df_clean['Size'] = df_clean['Size'].fillna('Unknown')\n",
    "\n",
    "# Standardize region names to title case\n",
    "df_clean['Region'] = df_clean['Region'].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Univariate Analysis <a name=\"univariate-analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Distribution of Units_Sold\n",
    "sns.histplot(df_clean['Units_Sold'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Units Sold')\n",
    "plt.xlabel('Units Sold')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Distribution of Profit\n",
    "sns.histplot(df_clean['Profit'], bins=20, kde=True, color='salmon')\n",
    "plt.title('Distribution of Profit')\n",
    "plt.xlabel('Profit')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Top 10 products by units sold\n",
    "top_products = df_clean.groupby('Product_Name')['Units_Sold'].sum().sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 Products by Units Sold:\\n\", top_products)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count of sales by region\n",
    "region_counts = df_clean['Region'].value_counts()\n",
    "sns.barplot(x=region_counts.index, y=region_counts.values, palette=\"viridis\")\n",
    "plt.title('Number of Sales by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bivariate Analysis <a name=\"bivariate-analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr = df_clean[['Units_Sold', 'MRP', 'Discount_Applied', 'Revenue', 'Profit']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Profit by Product Line\n",
    "sns.boxplot(x='Product_Line', y='Profit', data=df_clean)\n",
    "plt.title('Profit by Product Line')\n",
    "plt.xlabel('Product Line')\n",
    "plt.ylabel('Profit')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Revenue by Region\n",
    "sns.boxplot(x='Region', y='Revenue', data=df_clean)\n",
    "plt.title('Revenue by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Revenue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MRP vs Profit scatter plot\n",
    "sns.scatterplot(x='MRP', y='Profit', data=df_clean, alpha=0.6)\n",
    "plt.title('MRP vs Profit')\n",
    "plt.xlabel('MRP')\n",
    "plt.ylabel('Profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Handling Outliers <a name=\"handling-outliers\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Detect outliers in Profit using Z-score\n",
    "z_scores = np.abs(stats.zscore(df_clean['Profit']))\n",
    "outlier_threshold = 3\n",
    "outliers = df_clean[z_scores > outlier_threshold]\n",
    "print(f\"Detected {len(outliers)} outlier rows in Profit (Z-score > {outlier_threshold})\")\n",
    "\n",
    "# Show distribution before and after removing outliers\n",
    "df_no_outliers = df_clean[z_scores <= outlier_threshold]\n",
    "\n",
    "sns.histplot(df_no_outliers['Profit'], bins=20, kde=True, color='green')\n",
    "plt.title('Profit Distribution (No Outliers)')\n",
    "plt.xlabel('Profit')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Scaling / Transformation <a name=\"feature-scaling--transformation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Log transformation of Revenue to address skewness\n",
    "df_no_outliers['Log_Revenue'] = np.log1p(df_no_outliers['Revenue'])\n",
    "sns.histplot(df_no_outliers['Log_Revenue'], bins=20, kde=True, color='purple')\n",
    "plt.title('Log-Transformed Revenue Distribution')\n",
    "plt.xlabel('Log(Revenue + 1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Standardization of MRP\n",
    "mrp_mean = df_no_outliers['MRP'].mean()\n",
    "mrp_std = df_no_outliers['MRP'].std()\n",
    "df_no_outliers['MRP_zscore'] = (df_no_outliers['MRP'] - mrp_mean) / mrp_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Insights & Business Recommendations <a name=\"insights--business-recommendations\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"--- Key Insights ---\")\n",
    "# Most units sold are concentrated in a few product names.\n",
    "print(f\"Top selling product: {top_products.index[0]} with {top_products.iloc[0]} units.\")\n",
    "\n",
    "# Regions with most sales\n",
    "top_region = region_counts.idxmax()\n",
    "print(f\"Region with highest sales: {top_region}\")\n",
    "\n",
    "# Product lines show distinct profit profiles\n",
    "profit_per_line = df_no_outliers.groupby('Product_Line')['Profit'].mean().sort_values(ascending=False)\n",
    "print(\"Average profit by product line:\\n\", profit_per_line)\n",
    "\n",
    "# Discounts have a moderate positive correlation with units sold\n",
    "discount_corr = corr.loc['Units_Sold', 'Discount_Applied']\n",
    "print(f\"Correlation between Units Sold and Discount Applied: {discount_corr:.2f}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n--- Business Recommendations ---\")\n",
    "print(\"- Focus marketing on top-selling products and top-performing regions.\")\n",
    "print(\"- Analyze underperforming product lines for improvement or discontinuation.\")\n",
    "print(\"- Consider targeted discount strategies, as discounts moderately drive volume.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"--- Conclusion ---\")\n",
    "print(\"This Nike Sales EDA project demonstrates data cleaning, advanced analysis, and insight generation.\")\n",
    "print(\"The workflow and insights are applicable for real-world business decision support and showcase core data science skills.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
